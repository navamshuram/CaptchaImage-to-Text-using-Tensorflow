{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Captcha using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import all the packages\n",
    "import cv2\n",
    "import pickle\n",
    "import os.path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from helpers import resize_to_fit\n",
    "from tf_slim.layers import layers as _layers;\n",
    "\n",
    "train_graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all file names and folder names\n",
    "LETTER_IMAGES_FOLDER = \"extracted_letter_images\"\n",
    "MODEL_LABELS_FILENAME = \"model_labels.dat\"\n",
    "TEST_DATA_FOLDER = 'test_captcha2'\n",
    "CHECKPOINT = \"./train_model.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting preprocessed train images and it's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 20x20 pixel box\n",
    "    image = resize_to_fit(image, 20, 20)\n",
    "\n",
    "    # Add a third channel dimension to the image\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-2]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59143, 20, 20, 1)\n",
      "(59143, 1)\n"
     ]
    }
   ],
   "source": [
    "# Scale the raw pixel intensities to the range [0, 1] (this improves training)\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(np.expand_dims(labels, axis=1))\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59143, 18)\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels (letters) into one-hot encodings\n",
    "lb = LabelBinarizer().fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping from labels to one-hot encodings\n",
    "# We'll need this later when we use the model to decode what it's predictions mean\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = data.shape[0] # Number of training examples\n",
    "n_H = data.shape[1] # Images' height\n",
    "n_W = data.shape[2] # Images' width\n",
    "n_C = data.shape[3] # number of channels\n",
    "n_cls = labels.shape[1] # number of classes\n",
    "\n",
    "# Create placeholders for the train data and label\n",
    "with train_graph.as_default():\n",
    "    X = tf.compat.v1.placeholder(tf.float32, [None, n_H, n_W, n_C], name = 'input')\n",
    "    Y = tf.compat.v1.placeholder(tf.float32, [None, n_cls], name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights for the convolution layers\n",
    "# shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "with train_graph.as_default():    \n",
    "    W1 = tf.compat.v1.get_variable(\"W1\", [5, 5, 1, 20], initializer=tf.keras.initializers.GlorotNormal(\n",
    "    seed=0\n",
    "))\n",
    "    W2 = tf.compat.v1.get_variable(\"W2\", [5, 5, 20, 50], initializer=tf.keras.initializers.GlorotNormal(\n",
    "    seed=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fc2/BiasAdd:0\", shape=(None, 18), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_13756/3087344079.py:14: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  flatten_layer3 = tf.compat.v1.layers.flatten(max_pool_layer2)\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Create convolutional neural network\n",
    "with train_graph.as_default():\n",
    "    # Layer1 - Convolutional\n",
    "    conv_layer1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME', name = 'conv1')\n",
    "    relu_layer1 = tf.nn.relu(conv_layer1, name = 'relu1')\n",
    "    max_pool_layer1 = tf.nn.max_pool(relu_layer1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME', name = 'pool1')\n",
    "\n",
    "    # Layer2 - Convolutional\n",
    "    conv_layer2 = tf.nn.conv2d(max_pool_layer1, W2, strides=[1, 1, 1, 1], padding='SAME', name = 'conv2')\n",
    "    relu_layer2 = tf.nn.relu(conv_layer2, name = 'relu2')\n",
    "    max_pool_layer2 = tf.nn.max_pool(relu_layer2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME', name = 'pool2')\n",
    "\n",
    "    # Layer3 - Fully_Connected (Don't forget to flatten the previous layer)\n",
    "    flatten_layer3 = tf.compat.v1.layers.flatten(max_pool_layer2)\n",
    "    fc_layer3 = _layers.fully_connected(flatten_layer3, 500, activation_fn=tf.nn.relu, scope = 'fc1')\n",
    "\n",
    "    # Layer4 - Fully_Connected\n",
    "    fc_layer4 = _layers.fully_connected(fc_layer3, n_cls, activation_fn=None, scope = 'fc2')\n",
    "    print(fc_layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross entropy cost function\n",
    "with train_graph.as_default():\n",
    "    cross_entropy = tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=fc_layer4, labels=Y)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Use adam optimizer\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion: To pick random minibatches to train the model\n",
    "def random_mini_batches(train, labels, batch_size, seed):\n",
    "    # Always change the seed so that we randomize in different order\n",
    "    np.random.seed(seed)\n",
    "    # Make sure we shuffle both the train data and the label in the same order\n",
    "    p = np.random.permutation(len(train))\n",
    "    train = train[p]\n",
    "    labels = labels[p]\n",
    "    train_batches = []\n",
    "    label_batches = []\n",
    "    # Dividing the train data into minibatches\n",
    "    for batch_i in range(0, len(train)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        train_batch = train[start_i:start_i + batch_size]\n",
    "        label_batch = labels[start_i:start_i + batch_size]\n",
    "        train_batches.append(train_batch)\n",
    "        label_batches.append(label_batch)\n",
    "            \n",
    "    return train_batches, label_batches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed : Time usage 39 seconds\n",
      "\t- Cost after epoch 0: 0.530116\n",
      "Epoch 2 completed : Time usage 41 seconds\n",
      "\t- Cost after epoch 2: 0.004356\n",
      "Epoch 4 completed : Time usage 45 seconds\n",
      "\t- Cost after epoch 4: 0.002958\n",
      "Epoch 6 completed : Time usage 43 seconds\n",
      "\t- Cost after epoch 6: 0.002488\n",
      "Epoch 8 completed : Time usage 37 seconds\n",
      "\t- Cost after epoch 8: 0.002272\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "# Initialize all the hyperparameters\n",
    "seed = 3\n",
    "num_epochs=10\n",
    "minibatch_size=64\n",
    "costs = [] \n",
    "\n",
    "# Training the model\n",
    "with tf.compat.v1.Session(graph=train_graph) as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    # loader = tf.train.import_meta_graph(\"./\" + CHECKPOINT + '.meta')\n",
    "    # loader.restore(sess, CHECKPOINT)\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        minibatch_cost = 0\n",
    "        num_minibatches = int(m / minibatch_size)\n",
    "        seed = seed + 1\n",
    "        # Calling the random_mini_batches function to get the batches\n",
    "        train_batches, label_batches = random_mini_batches(data, labels, minibatch_size, seed)\n",
    "        \n",
    "        # Now train the model for each of that batches and calculate the minibatch cost\n",
    "        for batch_i in range(num_minibatches):\n",
    "            \n",
    "            # Choose the minibatches\n",
    "            minibatch_X = train_batches[batch_i]\n",
    "            minibatch_Y = label_batches[batch_i]\n",
    "            \n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "            \n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "        # Print the cost every 2 epoch\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch \"+str(epoch)+\" completed : Time usage \"+str(int(time.time()-start_time))+\" seconds\")\n",
    "            print(\"\\t- Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            # Don't forget to save the model\n",
    "            saver = tf.compat.v1.train.Saver() \n",
    "            saver.save(sess, CHECKPOINT)\n",
    "        if epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "            \n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.show()     \n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(fc_layer4, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "    # Calculate accuracy for the training data\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({X: data, Y: labels})   \n",
    "    print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the model on few tesrt data\n",
    "test_data_files = list(paths.list_images(TEST_DATA_FOLDER))\n",
    "print(test_data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the test images and making predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the model labels (so we can translate model predictions to actual letters)\n",
    "with open(MODEL_LABELS_FILENAME, \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "# Ignoring the INFO from the tensorflow\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "loaded_graph = tf.Graph()    \n",
    "\n",
    "# loop over the image paths\n",
    "for image_file in test_data_files:\n",
    "    \n",
    "    # Name of the image file is the ground truth for our predictions.\n",
    "    filename = os.path.basename(image_file)\n",
    "    captcha_correct_text = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Add some extra padding around the image\n",
    "    image = cv2.copyMakeBorder(image, 20, 20, 20, 20, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # threshold the image (convert it to pure black and white)\n",
    "    thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # find the contours (continuous blobs of pixels) the image\n",
    "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Hack for compatibility with different OpenCV versions\n",
    "    contours = contours[0]\n",
    "\n",
    "    letter_image_regions = []\n",
    "\n",
    "    # Now we can loop through each of the four contours and extract the letter\n",
    "    # inside of each one\n",
    "    for contour in contours:\n",
    "        # Get the rectangle that contains the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(contour.astype(np.int))\n",
    "        #(x, y, w, h) = cv2.findContours(contour)\n",
    "        # Compare the width and height of the contour to detect letters that\n",
    "        # are conjoined into one chunk\n",
    "        if w / h > 1.25:\n",
    "            # This contour is too wide to be a single letter!\n",
    "            # Split it in half into two letter regions!\n",
    "            half_width = int(w / 2)\n",
    "            letter_image_regions.append((x, y, half_width, h))\n",
    "            letter_image_regions.append((x + half_width, y, half_width, h))\n",
    "        else:\n",
    "            # This is a normal letter by itself\n",
    "            letter_image_regions.append((x, y, w, h))\n",
    "\n",
    "    # If we found more or less than 6 letters in the captcha, our letter extraction\n",
    "    # didn't work correcly. Skip the image.\n",
    "    if len(letter_image_regions) != 6:\n",
    "        continue\n",
    "\n",
    "    # Sort the detected letter images based on the x coordinate to make sure\n",
    "    # we are processing them from left-to-right so we match the right image\n",
    "    # with the right letter\n",
    "    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
    "\n",
    "    # Create an output image and a list to hold our predicted letters\n",
    "    output = cv2.merge([image] * 3)\n",
    "    predictions = []\n",
    "\n",
    "    # loop over the letters\n",
    "    for n,letter_bounding_box in enumerate(letter_image_regions):\n",
    "        # Grab the coordinates of the letter in the image\n",
    "        x, y, w, h = letter_bounding_box\n",
    "\n",
    "        # Extract the letter from the original image with a 2-pixel margin around the edge\n",
    "        letter_image = image[y - 2:y + h + 2, x - 2:x + w + 2]\n",
    "\n",
    "        # Re-size the letter image to 20x20 pixels to match training data\n",
    "        letter_image = resize_to_fit(letter_image, 20, 20)\n",
    "\n",
    "        # Turn the single image into a 4d list of images so that the Tensorflow can handle\n",
    "        letter_image = np.expand_dims(letter_image, axis=2)\n",
    "        letter_image = np.expand_dims(letter_image, axis=0)\n",
    "        \n",
    "        # Load the Tensorflow session\n",
    "        with tf.compat.v1.Session(graph=loaded_graph) as sess:\n",
    "            \n",
    "            # Load the saved model\n",
    "            loader = tf.compat.v1.train.import_meta_graph(CHECKPOINT + '.meta')\n",
    "            loader.restore(sess, CHECKPOINT)\n",
    "            \n",
    "            # Load the required parameters from the graph\n",
    "            final_layer = loaded_graph.get_tensor_by_name('fc2/BiasAdd:0')\n",
    "            input_layer = loaded_graph.get_tensor_by_name('input:0')\n",
    "            \n",
    "            # Making the predicitons\n",
    "            predict = tf.argmax(final_layer, 1)\n",
    "            output = predict.eval({input_layer: letter_image})\n",
    "            \n",
    "            # Append the correct letters to a list\n",
    "            predictions.append(lb.classes_[output[0]])\n",
    "    \n",
    "    # Let's print our results and determine if it's correct or not\n",
    "    print(\"Original Captcha - \" + captcha_correct_text)\n",
    "    print(\"Predicted Captcha - \" + ''.join(predictions))\n",
    "    if captcha_correct_text == ''.join(predictions):\n",
    "        print(\"---CORRECT---\")\n",
    "    else:\n",
    "        print(\"---WRONG---\")\n",
    "    \n",
    "    # Plotting the captcha image as well\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
